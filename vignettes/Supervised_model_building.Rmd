---
title: "Supervised Modelling Training for AutoFlow"
author: "Freya Woods"
date: "2024-12-02"
output: html_document
---

```{r setup, include=FALSE}
library(flowUtils)
library(flowCore)
library(flowWorkspace)
library(data.table)
library(Seurat)
library(ggcyto)
library(ggplot2)
library(viridis)
library(patchwork)
```

## Introduction / Motivation

AutoFlow is an Rshiny application we have developed to enable automated gating of flow cytometry data using both supervised and unsupervised machine learning. The latter only requires .fcs files and model parameters to be executed. However, the supervised version of the application requires the user to have pre-trained models for identifying cells.

In this vignette we demonstrate training and storing supervised cell identification models using 3 examples datasets; Mosmann Rare, Nilsson Rare, and Bone marrow microphysiological systems data.

For the Mosmann rare and Nilsson rare datasets we use upsampling due to the small number of labelled cells.

## Mosmann Rare
This dataset is a publicly available study (DOI: 10.1002/cyto.a.22445), containing ~400k cells with labels provided for 109 cells. Mosmann rare originates from peripheral blood cells with labels only provided only for a rare type of cell rare cytokine-producing influenza-specific T cells

```{r mosmann1}
# quick look at the data 
mosmann <- read.FCS("~/App_benchmarking_autoflow/Mosmann_rare.fcs", transformation=NULL)
autoplot(mosmann)

# columns included
colnames(mosmann)

# label column contains labels for rare cell type -- table to count
table(mosmann@exprs[,"label"])

```

```{r mosmann-wrangling}
expr_mosmann <- exprs(mosmann)
mosmann_df <- as.data.frame(expr_mosmann)

# select columns of interest
mosmann_df <- mosmann_df[, !(colnames(mosmann_df) %in% c("FSC-A", "FSC-W",
                                                                        "FSC-H", "SSC-A",
                                                                        "SSC-W", "SSC-H",
                                                                        "Live_Dead", "Time"))]
# scale and perform min-max normalisation
scale_mosmann <- scale(mosmann_df[,-ncol(mosmann_df)])
norm_minmax <- function(x){
  tmp = (x - min(x)) / (max(x) - min(x))
  return(tmp)
}
scale_mosmann_norm <- apply(scale_mosmann, 2, norm_minmax)

for_mdl_mosmann <- as.data.frame(scale_mosmann_norm)
for_mdl_mosmann$label <- as.factor(mosmann_df$label)
#rf_mdl_nilsson <-randomForest::randomForest(label~., for_mdl_nilsson)

```

```{r mosmann-model}
## 70% of the sample size
smp_size <- floor(0.70 * nrow(for_mdl_mosmann))


## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(for_mdl_mosmann)), size = smp_size)

colnames(for_mdl_mosmann) <- make.names(colnames(for_mdl_mosmann))
train <- for_mdl_mosmann[train_ind, ]
test <- for_mdl_mosmann[-train_ind, ]

orig <- count(train, label, name = "orig")

up_rec <- recipe(label ~ ., data = train) %>%
  # Bring the minority levels up to about 1000 each
  step_upsample(label, over_ratio = 1) %>%
  prep()

training <- up_rec %>%
  bake(new_data = NULL) %>%
  count(label, name = "training")
train_up <- up_rec %>%
  bake(new_data = NULL)
```

```{r mosmann-optim}
# train model
library(caret)
library(randomForest)
control <- trainControl(method="repeatedcv", number=5, repeats=1)
tunegrid <- expand.grid(.mtry=c(2:10))#, .ntree=c(1000, 1500, 2000, 2500))
set.seed(123)
metric <- "Accuracy"
custom <- train(label~., data=train_up, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
summary(custom)
plot(custom)

rf_up <- randomForest::randomForest(label~., train_under, mtry=2, ntree=1000)
test_idx <- predict(rf_up, test)
caret::confusionMatrix(test_idx, test$label, positive="1")

# save RDS
saveRDS(rf_up, "mosmann_model.rds")

```

```{r, customRF}
customRF <- list(type = "Classification", library = "randomForest", loop = NULL)
customRF$parameters <- data.frame(parameter = c("mtry", "ntree"), class = rep("numeric", 2), label = c("mtry", "ntree"))
customRF$grid <- function(x, y, len = NULL, search = "grid") {}
customRF$fit <- function(x, y, wts, param, lev, last, weights, classProbs, ...) {
    randomForest(x, y, mtry = param$mtry, ntree=param$ntree, ...)
}
customRF$predict <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
    predict(modelFit, newdata)
customRF$prob <- function(modelFit, newdata, preProc = NULL, submodels = NULL)
    predict(modelFit, newdata, type = "prob")
customRF$sort <- function(x) x[order(x[,1]),]
customRF$levels <- function(x) x$classes
customRF


```

## Nilsson Rare

Nilsson rare originates from haematopoietic cells, with labels provided for HSCs.

```{r nilsson-preprocessing}
nilsson <- read.FCS("Nilsson_rare.fcs", transformation = FALSE)


autoplot(nilsson)

nilsson_mat <- as.data.frame(exprs(nilsson))
summary(nilsson_mat)
nilsson_for_seurat <-nilsson_mat[, !(colnames(nilsson_mat) %in%
                                       c("FSC-A", "FSC-H", "FSC-W", "SSC-A", "Time"))]


nilsson_metadata_seurat <- data.frame("label" = nilsson_for_seurat$label)
scale_seurat_nilsson <- scale(nilsson_for_seurat[,-ncol(nilsson_for_seurat)])
scale_seurat_nilsson_norm <- apply(scale_seurat_nilsson, 2, norm_minmax)
```

```{r nilsson-optim}
# setup training parameters with caret
control <- trainControl(method="repeatedcv", number=10, repeats=3, summaryFunction = PPV)
tunegrid <- expand.grid(.mtry=c(2:10), .ntree=c(1000, 1500, 2000, 2500))
set.seed(123)
metric <- "PPV"
train_under <- sample_n(train_up, size=floor(0.1*nrow(train_up)))
PPV <- function (data,lev = NULL,model = NULL) {
   value <- posPredValue(data$pred,data$obs, positive = lev[1])
   c(PPV=value)
}
custom <- train(label~., data=train_under, method=customRF, metric=metric, tuneGrid=tunegrid, trControl=control)
summary(custom)
plot(custom)

```

```{r nilsson-mdl}

rf_up <- randomForest::randomForest(label~., train_up, mtry=2, ntree=1000)
test_idx <- predict(rf_up, test)
caret::confusionMatrix(test_idx, test$label, positive="1")
saveRDS(rf_up, "nilsson_mdl_out.RDS")
```

## Bone marrow microphysiological system (BM-MPS)
The BM-MPS dataset contains more cell types labelled from manual gating. 

In this training set we have samples from a time course study containing flow cytometry measurements at D0, D3, D7, D10, D14, D17, D21, D24, and D28.  

Each cell has a corresponding output from manual gating containing a matrix of TRUE and FALSE values for if a cell is in or out of a gate. E.g. an HSC would be CD34+CD38-. In this dataset to achieve the standard manual gating the hierarchy of assigning cell identities is seen below. However, this highlights the subjectivity of manual gating, be it that cells may fall into multiple categories.

```{r bm-mps-wrangling}
library(stringr) #for str_extract_all()
library(gtools) # for mixedsort

all_fcs <- list.files("~/App_benchmarking_autoflow/2021-5/Controls/", pattern = ".FCS", full.names = TRUE)

# Extract the "DXX" part using regular expressions
dxx_parts <- str_extract_all(all_fcs, "(?<=D)\\d+")
dxx_parts <- unlist(dxx_parts)

# Create a list to store files for each day
day_files <- list()

# Iterate through each day
for (i in seq_along(dxx_parts)) {
  day <- dxx_parts[i]
  file_name <- all_fcs[i]

  # Extract the prefix
  #prefix <- str_extract(all_fcs, "^\\d+_FCS_combined_")

  # Check if day already exists in list, if not, create a new list element
  if (!(day %in% names(day_files))) {
    day_files[[day]] <- list()
  }

  # Append file to list for the day
  day_files[[day]] <- c(day_files[[day]], paste0(all_fcs[i]))
}

# Print the list of files for each day
#print(day_files)
day_files_fin <- lapply(day_files, function(x){mixedsort(unlist(x))})

# read in flowset
read_day_flowset <- lapply(day_files_fin, read.FCS)

# convert to df for downstream
day_df <- lapply(read_day_flowset, function(x){fsApply(x, exprs)})

# read in gating matrices

gates_matrix <- list.files("~/App_benchmarking_autoflow/2021-5/Controls/", pattern = ".csv", full.names = TRUE)

# Extract the "DXX" part using regular expressions
gates_days <- str_extract_all(gates_matrix, "(?<=D)\\d+")
gates_days <- unlist(gates_days)
gates_matrix_read <- lapply(gates_matrix, read.table, check.names=FALSE)

# check ### 54 gates
lapply(gates_matrix_read, dim)

# convert matrices to a cell type label

# now for actual cell labels
sc <- list()
vc <- list()
hsc <- list()
mgk <- list()
ee <- list()
le <- list()
eg <- list()
lg <- list()
lm <- list()
ldp <- list()
for (i in 1:length(gates_matrix_read)){ # n cell types we track for
  sc[[i]] <- ifelse(gates_matrix_read[[i]]$`Single Cells` == TRUE, 1, 0)
  vc[[i]] <- ifelse(gates_matrix_read[[i]]$`Viable Cells` == TRUE, 1, 0)
  hsc[[i]] <- ifelse(gates_matrix_read[[i]]$`CD34+ CD38- HSCs V3` == TRUE &
                       gates_matrix_read[[i]]$`CD41- CD16-` == TRUE &
                       gates_matrix_read[[i]]$`CD13-`==TRUE, 1, 0)
  mgk[[i]] <- ifelse(gates_matrix_read[[i]]$`CD36+- Megakaryocytes V3` == TRUE &
                       gates_matrix_read[[i]]$`CD13-` == TRUE &
                       gates_matrix_read[[i]]$`CD13-/CD41+ CD16-` ==TRUE, 1, 0)
  ee[[i]] <- ifelse(gates_matrix_read[[i]]$`CD71+ CD235+- Early Erythroid V3` == TRUE &
                      gates_matrix_read[[i]]$`CD13-`==TRUE &
                      gates_matrix_read[[i]]$`CD13-/CD36+` ==TRUE, 1, 0)
  le[[i]] <-  ifelse(gates_matrix_read[[i]]$`CD71+- CD235+ Later Erythroid V3` == TRUE &
                       gates_matrix_read[[i]]$`CD13-`== TRUE &
                       gates_matrix_read[[i]]$`CD13-/CD36-` ==TRUE, 1, 0) #&
  #all_gates_matrix$`Viable Cells/CD36-`
  eg[[i]] <-  ifelse(gates_matrix_read[[i]]$`CD41- CD16- Early Granulocytes` == TRUE &
                       gates_matrix_read[[i]]$`CD13+ CD235-` == TRUE, 1, 0)
  lg[[i]] <-  ifelse(gates_matrix_read[[i]]$`CD41- CD16+ Late Granulocytes` == TRUE &
                       gates_matrix_read[[i]]$`CD13+ CD235-` == TRUE, 1, 0)
  #all_gates_matrix$, 1, 0)
  lm[[i]] <-  ifelse(gates_matrix_read[[i]]$`CD36+ CD16+- Late Monocytes` == TRUE &
                       gates_matrix_read[[i]]$`CD13+ CD235-` == TRUE &
                       gates_matrix_read[[i]]$`CD41-` == TRUE, 1, 0)
  ldp[[i]] <-  ifelse(gates_matrix_read[[i]]$`CD34+ CD38+ Lineage Differentiated Progenitors` == TRUE, 1, 0)

}

#
all_positive_matrix <- list()
for (i in 1:length(gates_matrix_read)){
  all_positive_matrix[[i]] <- data.frame(do.call("cbind", list(vc[[i]], sc[[i]], hsc[[i]], mgk[[i]], ee[[i]], le[[i]],
                                                               eg[[i]], lg[[i]], lm[[i]], ldp[[i]])))
  colnames(all_positive_matrix[[i]]) <- c("vc", "sc", "hsc", "mgk", "ee", "le", "eg", "lg", "lm", "ldp")
  all_positive_matrix[[i]]$multi_cell <- rowSums(all_positive_matrix[[i]][,3:10])
  #table(all_positive_matrix$multi_cell)
}

label_origin_hierarchy_2021_05 <-list()
for(i in 1:length(gates_matrix_read)){
  label_origin_hierarchy_2021_05[[gates_days[i]]] <- ifelse(all_positive_matrix[[i]]$vc == "0", "non-viable",
                                                ifelse(all_positive_matrix[[i]]$sc == "0", "debris/doublet",
                                                       ifelse(all_positive_matrix[[i]]$lm == "1", "Late Monocytes",
                                                              ifelse(all_positive_matrix[[i]]$lg  == "1", "Late Granulocytes",
                                                                     ifelse(all_positive_matrix[[i]]$eg  == "1" , "Early Granulocytes",
                                                                            ifelse(all_positive_matrix[[i]]$ee  == "1",  "Early Erythroid",
                                                                                   ifelse(all_positive_matrix[[i]]$le  == "1", "Later Erythroid",
                                                                                          ifelse(all_positive_matrix[[i]]$mgk  == "1", "Megakaryocytes",

                                                                                                 ifelse(all_positive_matrix[[i]]$hsc  == "1", "HSCs",
                                                                                                        ifelse(all_positive_matrix[[i]]$ldp  == "1", "Progenitors", "Unknown"))))))))))
}

lapply(label_origin_hierarchy_2021_05, function(x){table(x)/length(x)*100})


# match label matrix with data
lapply(label_origin_hierarchy_2021_05, length)

lapply(day_df,dim)


day_df <- lapply(day_df, as.data.frame)
# Iterate through each column of day_df
for (day in names(day_df)) {
  # Check if day exists in label_origin_hierarchy_2021_05
  if (day %in% names(label_origin_hierarchy_2021_05)) {
    # Add the labels as a new column to day_df
    day_df[[day]]$label = label_origin_hierarchy_2021_05[[day]]
  } else {
    # If day does not exist, fill with NA
    day_df[[day]] <- rep(NA, nrow(day_df[[day]]))
  }
}

# Print day_df to verify
lapply(day_df, dim)


# Add the labels as a new column to day_df
#day_df$labels <- unlist(labels


# build model on day 1, and validate with
days_viab <- lapply(day_df, function(x){x[!(x$label %in% c("debris/doublet", "non-viable", "Unknown") ),
                                          colnames(x) %like% "Comp" | colnames(x) == "label"] })
#days_viab <- lapply(days_viab, make.names)
for(i in 1:length(days_viab)){
  colnames(days_viab[[i]]) <- make.names(colnames(days_viab[[i]]))
  days_viab[[i]]$label <- factor(days_viab[[i]]$label)
}

library(randomForest)
train <- days_viab[["14"]]
mean_train <- apply(train[,colnames(train) != "label"], 2, mean)
sd_train <- apply(train[,colnames(train) != "label"], 2, sd)

train_norm<- train
train_norm[,1:(ncol(train_norm)-1)] <- scale(train[,1:(ncol(train)-1)],
                                             center=mean_train, scale=sd_train)
test_norm <- days_viab[[1]]
test_norm[,1:(ncol(days_viab[[1]])-1)] <- scale(test_norm[,1:(ncol(days_viab[[1]])-1)],
                                                center=mean_train, scale=sd_train)

days_norm <- lapply(days_viab, function(x){
  x[,1:(ncol(x)-1)] <- scale(x[,1:(ncol(x)-1)], center=mean_train, scale=sd_train)
  return(x)
})
trf <- randomForest(label~., train_norm )
test_trf <- predict(trf, test_norm)
test_trf_nonorm <- predict(trf, days_viab[[1]])

caret::confusionMatrix(days_viab[[1]]$label, test_trf)
caret::confusionMatrix(test_norm$label, test_trf)


#train model
library(caret)
library(randomForest)
control <- trainControl(method="repeatedcv", number=5, repeats=1)
tunegrid <- expand.grid(.ntree=c(1000,1500,2000,2500))#expand.grid(.mtry=c(2:10))#, .ntree=c(1000, 1500, 2000, 2500))
set.seed(123)
metric <- "Accuracy"
custom <- train(label~., data=train_norm, method="rf", metric=metric, tuneGrid=tunegrid, trControl=control)
summary(custom)
plot(custom)


mdl_mps <- randomForest(label~., train_norm, mtry=6, ntree=1000)
test_all_days <- days_norm
test_all_days <- test_all_days[c("0", "3", "7", "10", "17", "21", "24", "28")]
test_all_comb <- do.call("rbind", test_all_days)
test_all <- predict(mdl_mps, test_all_comb)#lapply(days_norm, predict, object=mdl_mps)
confusionMatrix(test_all_comb$label, test_all)


confusionMatrix(days_norm[[1]]$label, test_all[[1]])
confusionMatrix(days_norm[[2]]$label, test_all[[2]])
confusionMatrix(days_norm[[3]]$label, test_all[[3]])
confusionMatrix(days_norm[[4]]$label, test_all[[4]])
confusionMatrix(days_norm[[5]]$label, test_all[[5]])
confusionMatrix(days_norm[[6]]$label, test_all[[6]])
confusionMatrix(days_norm[[7]]$label, test_all[[7]])
confusionMatrix(days_norm[[8]]$label, test_all[[8]])
confusionMatrix(days_norm[[9]]$label, test_all[[9]])


```

```{r read_in_preprocess_BMMPS}
# Load required libraries
library(stringr) # For str_extract_all()
library(gtools) # For mixedsort
library(flowCore) # For handling FCS files
library(randomForest)
library(caret)

# Paths and file listings
fcs_path <- "~/App_benchmarking_autoflow/2021-5/Controls/"
gates_path <- fcs_path

all_fcs <- list.files(fcs_path, pattern = ".FCS", full.names = TRUE)
gates_matrix <- list.files(gates_path, pattern = ".csv", full.names = TRUE)

# Extract day identifiers (e.g., D7) from filenames
extract_days <- function(files) {
  days <- str_extract_all(files, "(?<=D)\\d+")
  unlist(days)
}

fcs_days <- extract_days(all_fcs)
gates_days <- extract_days(gates_matrix)

# Match FCS files to their corresponding gating matrices
match_files_to_days <- function(fcs_files, fcs_days, gates_files, gates_days) {
  matched <- lapply(unique(fcs_days), function(day) {
    fcs_matched <- fcs_files[fcs_days == day]
    gates_matched <- gates_files[gates_days == day]
    list(fcs = mixedsort(fcs_matched), gates = gates_matched)
  })
  names(matched) <- unique(fcs_days)
  matched
}

matched_files <- match_files_to_days(all_fcs, fcs_days, gates_matrix, gates_days)

# Read FCS files and gating matrices
read_fcs_files <- function(fcs_list) {
  lapply(fcs_list, read.FCS)
}

read_gates <- function(gates_list) {
  lapply(gates_list, read.table, check.names = FALSE, header = TRUE)
}

# Label cells based on gating matrices with a revised hierarchy
label_cells <- function(gates_data) {
  labels <- list()
  for (i in seq_along(gates_data)) {
    gates <- gates_data[[i]]
    labels[[i]] <- ifelse(gates$`Viable Cells` == FALSE, "Non-Viable",
                   ifelse(gates$`Single Cells` == FALSE, "Debris/Doublet",
                   ifelse(gates$`CD36+ CD16+- Late Monocytes` == TRUE, "Late Monocytes",
                   ifelse(gates$`CD41- CD16+ Late Granulocytes` == TRUE, "Late Granulocytes",
                   ifelse(gates$`CD41- CD16- Early Granulocytes` == TRUE, "Early Granulocytes",
                   ifelse(gates$`CD71+ CD235+- Early Erythroid V3` == TRUE, "Early Erythroid",
                   ifelse(gates$`CD71+- CD235+ Later Erythroid V3` == TRUE, "Later Erythroid",
                   ifelse(gates$`CD36+- Megakaryocytes V3` == TRUE, "Megakaryocytes",
                   ifelse(gates$`CD34+ CD38- HSCs V3` == TRUE, "HSCs",
                   ifelse(gates$`CD34+ CD38+ Lineage Differentiated Progenitors` == TRUE, "Progenitors",
                          "Unknown"))))))))))
  }
  labels
}

# Build model on one day and validate on others
build_and_validate_model <- function(train_day, test_days, norm_params = NULL) {
  train_data <- train_day
  
  if (is.null(norm_params)) {
    norm_params <- list(mean = colMeans(train_data[, -ncol(train_data)]),
                        sd = apply(train_data[, -ncol(train_data)], 2, sd))
  }
  train_data[, -ncol(train_data)] <- scale(train_data[, -ncol(train_data)],
                                           center = norm_params$mean,
                                           scale = norm_params$sd)

  model <- randomForest(label ~ ., data = train_data)

  predictions <- lapply(test_days, function(test_data) {
    test_data[, -ncol(test_data)] <- scale(test_data[, -ncol(test_data)],
                                           center = norm_params$mean,
                                           scale = norm_params$sd)
    predict(model, test_data)
  })

  list(model = model, predictions = predictions)
}

# Example workflow
all_labels <- list()
all_fcs_data <- list()

for (day in names(matched_files)) {
  fcs_files <- matched_files[[day]]$fcs
  gates_files <- matched_files[[day]]$gates

  fcs_data <- read_fcs_files(fcs_files)
  gates_data <- read_gates(gates_files)

  labels <- label_cells(gates_data)
  all_labels[[day]] <- labels
  all_fcs_data[[day]] <- fcs_data
}


```

```{r bm-mps-optim}
# Combine and process data for modeling
holdout_day <- "28"
remaining_days <- setdiff(names(all_fcs_data), holdout_day)


#Combine flowframes for a particular day into a single data frame
combine_day_data <- function(day_frames) {
  combined_data <- do.call(rbind, lapply(day_frames, function(flowframe) {
    data <- exprs(flowframe)  # Extract expression data from flowframe
    data <- as.data.frame(data)
    data[, grep("Comp", colnames(data), value = TRUE)]  # Keep only "Comp" columns
  }))
  return(combined_data)
}

#  Add the day and label columns to the combined data
add_label_column <- function(combined_data, day_label, day_index) {
  # Add the 'day' column with the day index repeated for the number of rows
  combined_data$day <- rep(day_index, nrow(combined_data))
  
  # Add the 'label' column with the actual labels from all_labels for this day
  day_labels <- all_labels[[day_index]][[1]]  # Extract labels for the specific day
  combined_data$label <- day_labels[1:nrow(combined_data)]  # Ensure correct length
  
  return(combined_data)
}

# Now, you can use these functions as follows:

processed_data <- lapply(names(all_fcs_data), function(day) {
  print(paste("Processing day:", day))
  
  # Step 1: Combine the flowframes
  combined_data <- combine_day_data(all_fcs_data[[day]])
  
  # Step 2: Add the 'day' and 'label' columns
  labeled_data <- add_label_column(combined_data, day, day)  # day here refers to the index in all_labels
  
  return(labeled_data)
})

# Remove debris/non-viable cells and non-assigned
all_data <- do.call(rbind, processed_data)
all_data_clean <- all_data[!(all_data$label %in% c("Unknown", "Non-Viable", "Debris/Doublet")),]

# also remove columns V525.50 (Live/Dead marker), and FITC - EdU (S-phase rather than phenotypic)
all_data_clean <- all_data_clean[, !(colnames(all_data_clean) %in% c("Comp-V525_50-A", "Comp-FITC-A"))]

# Split into training and validation data
validation_data <- all_data_clean[all_data_clean$day == holdout_day,]
training_data <- all_data_clean[all_data_clean$day != holdout_day,]

# Normalize the training data
mean_train <- apply(training_data[, !(colnames(training_data) %in% c("label","day"))], 2, mean)
sd_train <- apply(training_data[, !(colnames(training_data) %in% c("label","day"))], 2, sd)

training_data[, !(colnames(training_data) %in% c("label","day"))] <- scale(training_data[, !(colnames(training_data) %in% c("label","day"))], 
                                                             center = mean_train, scale = sd_train)

# Normalize the validation data
validation_data[, !(colnames(training_data) %in% c("label","day"))] <- scale(validation_data[, !(colnames(training_data) %in% c("label","day"))],) 


```

```{r bm-mps-mdl}
library(caret)
# Downsample the training data
set.seed(123)
# Clean the training and validation data by removing the 'day' column
training_data_clean <- training_data[, !colnames(training_data) %in% "day"]
validation_data_clean <- validation_data[, !colnames(validation_data) %in% "day"]
training_data_clean$label <- as.factor(training_data_clean$label)
validation_data_clean$label <- as.factor(validation_data_clean$label)

# Downsample the training data to balance classes
training_data_downsampled <- downSample(x = training_data_clean[, !colnames(training_data_clean) %in% "label"], 
                                        y = training_data_clean$label, yname = "label")

library(randomForest)
control <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
tunegrid <- expand.grid(mtry = c(2:8))#, ntree = c(1000, 1500, 2000))
metric <- "Accuracy"
# Train the model using cross-validation
model <- train(label ~ ., data = training_data_downsampled, method = "rf", metric = metric, 
               tuneGrid = tunegrid, trControl = control, ntree = 1000)

# Validate the model on the hold-out day
validation_predictions <- predict(model, validation_data_clean)
validation_conf_matrix <- confusionMatrix(validation_predictions, validation_data_clean$label)

# Print validation results
print(validation_conf_matrix)

# Get the predicted probabilities for AUC calculation
validation_probs <- predict(model, validation_data_clean, type = "prob")

# Calculate and plot the ROC curve and AUC
roc_curve <- roc(validation_data_clean$label, validation_probs[, 2])
plot(roc_curve, main = "ROC Curve", col = "blue")
text(0.8, 0.2, paste("AUC = ", round(auc(roc_curve), 2)), col = "blue")

# Print the AUC value
print(paste("AUC: ", round(auc(roc_curve), 2)))


```
