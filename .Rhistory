slopes <- lapply(fits, function(x){coef(x)[2]})
intercepts <- lapply(fits, function(x){coef(x)[1]})
#  remove_outliers(x$"FSC-H", x$"FSC-A")})
sc_only <- list()
for (i in 1:length(all_fc_int)){
remove_these <- remove_outliers(all_fc_int[[i]]@exprs[,"FSC.H"], all_fc_int[[i]]@exprs[, "FSC.A"],
slope = slopes[[i]],
intercept = intercepts[[i]])
dat_tmp <- all_fc_int[[i]]
sc_only[[i]] <- dat_tmp[-remove_these,]
sc_only[[i]] <- sc_only[[i]][sc_only[[i]]@exprs[,"Viability"] < 2,] # cell viability
seurat_dat <- lapply(sc_only, flowCore::exprs)
meta_file <- list()
for(i in 1:length(seurat_dat)){
meta_file[[i]] <- data.frame(t(replicate(nrow(seurat_dat[[i]]),fn_metadata[[i]])))
colnames(meta_file[[i]]) <- paste0("filename", 1:ncol(meta_file[[i]]))
}
seurat_dat_comb <- as.data.frame(do.call("rbind", seurat_dat))
#edu_mdl <- mclust::Mclust(seurat_dat_comb[,c("EdU")], 2)
#edu_binary <- ifelse(edu_mdl$classification == which.min(edu_mdl$parameters$mean), 0, 1)
seurat_meta_comb <<- do.call("rbind", meta_file)
#seurat_meta_comb$proliferation <- edu_binary
rownames(seurat_dat_comb) <- rownames(seurat_meta_comb)
}
} else if(input$preprocess == "No"){
all_exprs <- lapply(all_read, function(x){flowCore::exprs(x)})
meta_file <- list()
for(i in 1:length(all_exprs)){
meta_file[[i]] <- data.frame(t(replicate(nrow(all_exprs[[i]]),fn_metadata[[i]])))
colnames(meta_file[[i]]) <- paste0("filename", 1:ncol(meta_file[[i]]))
}
seurat_dat_comb <<- as.data.frame(do.call("rbind", all_exprs))
seurat_meta_comb <<- do.call("rbind", meta_file)
rownames(seurat_dat_comb) <<- rownames(seurat_meta_comb)
}
fn_metadata
#####
# # pre-process data
all_ff <- lapply(all_read, preprocess_2)
# rename with marker_panel
all_ff_rename <- all_ff
for(j in 1:length(all_ff_rename)){
all_ff_rename[[j]] <- all_ff[[j]]
for(i in 1:length(marker_panel$Marker)){
flowCore::colnames(all_ff_rename[[j]])[which(grepl(marker_panel$Fluorochrome[i], flowCore::colnames(all_ff_rename[[j]])))] <- marker_panel$Marker[i]
}
# subset to get only cols we care about:
#fs_to_mat_rename[[j]] <- fs_to_mat_rename[[j]][,colnames(fs_to_mat_rename[[j]]) %in% marker_list$Marker |
#                                                colnames(fs_to_mat_rename[[j]]) %in% c("FSC.A", "SSC.A", "FITC.A")]
}
# remove debris with gauss mix clustering (MCLUST) on V525.50
# select channels
all_ff_a <- lapply(all_ff_rename, channel_select)
#' @export
# functions
# pre-process functions
preprocess_2 <- function(ff){
ff <- flowCore::compensate(ff, flowCore::keyword(ff)$SPILL)
ff <- flowCore::transform(ff,
flowCore::estimateLogicle(ff,
colnames(flowCore::keyword(ff)$SPILL)))
#scale(ff)
}
channel_select <- function(ff){
library(data.table)
ff = ff[,c((flowCore::colnames(ff) %like% ".A") | flowCore::colnames(ff) %like% "Time") | flowCore::colnames(ff) %like% "FSC.H" | flowCore::colnames(ff) %in% marker_panel$Marker]
ff
}
# Functions for .fsc data importing and mapping to metadata
# Below sections are to allow for cbind.fill -- package origin had depreciated
cbind_fill<-function(...,fill=NULL)
{
inputs<-list(...)
inputs<-lapply(inputs,vert)
maxlength<-max(unlist(lapply(inputs,len)))
bufferedInputs<-lapply(inputs,buffer,length.out=maxlength,fill,preserveClass=FALSE)
return(Reduce(cbind.data.frame,bufferedInputs))
}
vert<-function(object)
{
#result<-as.data.frame(cbind(as.matrix(object)))
if(is.list(object))
object<-cbind(object)
object<-data.frame(object)
return(object)
}
len <- function(data)
{
result<-ifelse(is.null(nrow(data)),length(data),nrow(data))
return(result)
}
buffer<-function(x,length.out=len(x),fill=NULL,preserveClass=TRUE)
{
xclass<-class(x)
input<-lapply(vert(x),unlist)
results<-as.data.frame(lapply(input,rep,length.out=length.out))
if(length.out>len(x) && !is.null(fill))
{
results<-t(results)
results[(length(unlist(x))+1):length(unlist(results))]<-fill
results<-t(results)
}
if(preserveClass)
results<-as2(results,xclass)
return(results)
}
# Now process each with the preprocess function which applies the set spillover file and normalises with biexponential logicle function
preprocess <- function(ff) {
ff <- compensate(ff, ff@description$SPILL)
ff <- transform(ff, flowCore::transformList(colnames(ff@description$SPILL), flowCore::logicleTransform()))
ff@exprs <- scale(ff@exprs)
return(ff)
}
# function to convert wellIDs to match those attached to flowjo objects
checkWellNames = function(wellNames) {
#' Check and convert well names to the appropriate format
#' E.g. A1 -> A01
#'
#' @param wellNames String vector (e.g. c("A1", "A2", "B3", "B4"))
#'
#' @return String vector
#'
o = wellNames
rows = substr(wellNames, 1, 1)
stopifnot(all(rows %in% toupper(letters)[1:8]))
columns = as.integer(substr(wellNames, 2, 10))
stopifnot(all(columns >= 1 & columns <= 12))
columns = as.character(columns)
columns = sapply(columns, function(x) {
if (nchar(x) == 1) {
return(paste0("0", x))
} else {
return(x)
}
})
return(paste0(rows, columns))
}
# Function to extract labels from fcs file paired with workspace --
workspace_cell_labels <- function(flowset, workspace, cell_types=cell_types_fixed, ws_group){
groups = fj_ws_get_sample_groups(open_flowjo_xml(workspace))#, execute = FALSE)
group_pos = groups[match(ws_group, groups$groupName), 2] + 1 # returns the group ID for the matched group +1 as the numbering begins at 0
gating_manual = GetFlowJoLabels(flowset,
workspace,
group = group_pos,
cellTypes = cell_types,
get_data = TRUE)
manual_labels = do.call("c",lapply(gating_manual,function(x){x$manual}))
rm(gating_manual)
return(manual_labels)
}
# wiht this the condition is a on points that deviate from FSC.H ~ FSC.A linearly, plus removing debrit (v. small vals in both)
# Function to remove data 5% from the line
remove_outliers <- function(x, y, p = 0.05, slope, intercept) {
# Get the predicted values
predicted <- slope * x + intercept
# Calculate the residuals
residuals <- y - predicted
# Calculate the threshold for outliers
threshold <- quantile(abs(residuals), 1 - p)
# Identify the outliers
outliers <- which(abs(residuals) > threshold)
# Return the new data without outliers
return(outliers)
}
log_transform_with_shift <- function(data) {
min_value <- min(data)
# Calculate the shift based on the minimum value
shift <- ifelse(min_value < 0, abs(min_value) + 1, 0)
# Log-transform the adjusted data
log_transformed_data <- log(data + shift)
return(log_transformed_data)
}
cell_labelling_bm <- function(seur) {
library(stringr)
seur$cell_type <- ifelse(str_detect(seur$assignment, "CD34\\+"), "HSC",
ifelse(str_detect(seur$assignment, "CD38\\+"), "LDPs",
ifelse(str_detect(seur$assignment, "CD13\\+") & str_detect(seur$assignment, "CD16\\+"), "Late Granulocytes",
ifelse(str_detect(seur$assignment, "CD13\\+") & str_detect(seur$assignment, "CD36\\+"), "Late Monocytes",
ifelse(str_detect(seur$assignment, "CD13\\+"), "Early Granulocytes",
ifelse(str_detect(seur$assignment, "CD36\\+") & str_detect(seur$assignment, "CD71\\+"), "Early Erythroid",
ifelse(str_detect(seur$assignment, "CD41\\+") | str_detect(seur$assignment, "CD42b\\+"), "Megakaryocytes",
ifelse(str_detect(seur$assignment, "CD235a\\+"), "Late Erythroid", seur$assignment))))))))
return(seur)
}
norm_minmax <- function(x){
tmp = (x - min(x)) / (max(x) - min(x))
return(tmp)
}
# remove debris with gauss mix clustering (MCLUST) on V525.50
# select channels
all_ff_a <- lapply(all_ff_rename, channel_select)
# remove margin events using PeacoQC's RemoveMargins()
all_fc_margin <- lapply(all_ff_a, function(x){PeacoQC::RemoveMargins(x, channels=1:ncol(x))})
# QC in time using PeacoQC selecting only time parameter
all_fc_qc <- lapply(all_fc_margin, function(x){tryCatch(PeacoQC::PeacoQC(x, report=FALSE,channels=c("Time"), save_fcs = FALSE)$FinalFF)})
library(mclust)
# debris removed with threshold <FSC.H/A 0.3*10^5
all_fc_int <- lapply(all_fc_qc, function(x, threshold = 0.3*10^5){x[x@exprs[,"FSC.A"] > threshold & x@exprs[,"FSC.H"] > threshold,]})
# single cell identification with linear regression model
# Fit a linear regression line
fits <- lapply(all_fc_int, function(x){
lm(x@exprs[, "FSC.H"] ~ x@exprs[, "FSC.A"])})
# Get the slope and intercept of the line
slopes <- lapply(fits, function(x){coef(x)[2]})
intercepts <- lapply(fits, function(x){coef(x)[1]})
sc_only <- list()
for (i in 1:length(all_fc_int)){
remove_these <- remove_outliers(all_fc_int[[i]]@exprs[,"FSC.H"], all_fc_int[[i]]@exprs[, "FSC.A"],
slope = slopes[[i]],
intercept = intercepts[[i]])
dat_tmp <- all_fc_int[[i]]
sc_only[[i]] <- dat_tmp[-remove_these,]
sc_only[[i]] <- sc_only[[i]][sc_only[[i]]@exprs[,"Viability"] < 2,] # cell viability
seurat_dat <- lapply(sc_only, flowCore::exprs)
meta_file <- list()
for(i in 1:length(seurat_dat)){
meta_file[[i]] <- data.frame(t(replicate(nrow(seurat_dat[[i]]),fn_metadata[[i]])))
colnames(meta_file[[i]]) <- paste0("filename", 1:ncol(meta_file[[i]]))
}
seurat_dat_comb <- as.data.frame(do.call("rbind", seurat_dat))
#edu_mdl <- mclust::Mclust(seurat_dat_comb[,c("EdU")], 2)
#edu_binary <- ifelse(edu_mdl$classification == which.min(edu_mdl$parameters$mean), 0, 1)
seurat_meta_comb <<- do.call("rbind", meta_file)
#seurat_meta_comb$proliferation <- edu_binary
rownames(seurat_dat_comb) <- rownames(seurat_meta_comb)
}
if(input$preprocess == "Yes"){
cat("\n Running compensation and transformation \n")
#####
# # pre-process data
all_ff <- lapply(all_read, preprocess_2)
# rename with marker_panel
all_ff_rename <- all_ff
for(j in 1:length(all_ff_rename)){
all_ff_rename[[j]] <- all_ff[[j]]
for(i in 1:length(marker_panel$Marker)){
flowCore::colnames(all_ff_rename[[j]])[which(grepl(marker_panel$Fluorochrome[i], flowCore::colnames(all_ff_rename[[j]])))] <- marker_panel$Marker[i]
}
# subset to get only cols we care about:
#fs_to_mat_rename[[j]] <- fs_to_mat_rename[[j]][,colnames(fs_to_mat_rename[[j]]) %in% marker_list$Marker |
#                                                colnames(fs_to_mat_rename[[j]]) %in% c("FSC.A", "SSC.A", "FITC.A")]
}
# remove debris with gauss mix clustering (MCLUST) on V525.50
# select channels
all_ff_a <- lapply(all_ff_rename, channel_select)
# remove margin events using PeacoQC's RemoveMargins()
all_fc_margin <- lapply(all_ff_a, function(x){PeacoQC::RemoveMargins(x, channels=1:ncol(x))})
# QC in time using PeacoQC selecting only time parameter
all_fc_qc <- lapply(all_fc_margin, function(x){tryCatch(PeacoQC::PeacoQC(x, report=FALSE,channels=c("Time"), save_fcs = FALSE)$FinalFF)})
library(mclust)
# debris removed with threshold <FSC.H/A 0.3*10^5
all_fc_int <- lapply(all_fc_qc, function(x, threshold = 0.3*10^5){x[x@exprs[,"FSC.A"] > threshold & x@exprs[,"FSC.H"] > threshold,]})
# single cell identification with linear regression model
# Fit a linear regression line
fits <- lapply(all_fc_int, function(x){
lm(x@exprs[, "FSC.H"] ~ x@exprs[, "FSC.A"])})
# Get the slope and intercept of the line
slopes <- lapply(fits, function(x){coef(x)[2]})
intercepts <- lapply(fits, function(x){coef(x)[1]})
#  remove_outliers(x$"FSC-H", x$"FSC-A")})
sc_only <- list()
for (i in 1:length(all_fc_int)){
remove_these <- remove_outliers(all_fc_int[[i]]@exprs[,"FSC.H"], all_fc_int[[i]]@exprs[, "FSC.A"],
slope = slopes[[i]],
intercept = intercepts[[i]])
dat_tmp <- all_fc_int[[i]]
sc_only[[i]] <- dat_tmp[-remove_these,]
sc_only[[i]] <- sc_only[[i]][sc_only[[i]]@exprs[,"Viability"] < 2,] # cell viability
seurat_dat <- lapply(sc_only, flowCore::exprs)
meta_file <- list()
for(i in 1:length(seurat_dat)){
meta_file[[i]] <- data.frame(t(replicate(nrow(seurat_dat[[i]]),fn_metadata[[i]])))
colnames(meta_file[[i]]) <- paste0("filename", 1:ncol(meta_file[[i]]))
}
seurat_dat_comb <- as.data.frame(do.call("rbind", seurat_dat))
#edu_mdl <- mclust::Mclust(seurat_dat_comb[,c("EdU")], 2)
#edu_binary <- ifelse(edu_mdl$classification == which.min(edu_mdl$parameters$mean), 0, 1)
seurat_meta_comb <<- do.call("rbind", meta_file)
#seurat_meta_comb$proliferation <- edu_binary
rownames(seurat_dat_comb) <- rownames(seurat_meta_comb)
}
} else if(input$preprocess == "No"){
all_exprs <- lapply(all_read, function(x){flowCore::exprs(x)})
meta_file <- list()
for(i in 1:length(all_exprs)){
meta_file[[i]] <- data.frame(t(replicate(nrow(all_exprs[[i]]),fn_metadata[[i]])))
colnames(meta_file[[i]]) <- paste0("filename", 1:ncol(meta_file[[i]]))
}
seurat_dat_comb <<- as.data.frame(do.call("rbind", all_exprs))
seurat_meta_comb <<- do.call("rbind", meta_file)
rownames(seurat_dat_comb) <<- rownames(seurat_meta_comb)
}
all_exprs <- lapply(all_read, function(x){flowCore::exprs(x)})
meta_file <- list()
for(i in 1:length(all_exprs)){
meta_file[[i]] <- data.frame(t(replicate(nrow(all_exprs[[i]]),fn_metadata[[i]])))
colnames(meta_file[[i]]) <- paste0("filename", 1:ncol(meta_file[[i]]))
}
seurat_dat_comb <<- as.data.frame(do.call("rbind", all_exprs))
seurat_meta_comb <<- do.call("rbind", meta_file)
rownames(seurat_dat_comb) <<- rownames(seurat_meta_comb)
seurat_dat_comb <<- as.data.frame(do.call("rbind", all_exprs))
seurat_meta_comb <<- do.call("rbind", meta_file)
rownames(seurat_dat_comb) <<- rownames(seurat_meta_comb)
all_exprs
all_exprs
seurat_dat_comb <<- as.data.frame(do.call("rbind", all_exprs))
seurat_dat_comb
seurat_dat_comb <<- as.data.frame(do.call("rbind", all_exprs))
seurat_meta_comb <<- do.call("rbind", meta_file)
rownames(seurat_dat_comb) <<- rownames(seurat_meta_comb)
seurat_dat_comb
rownames(seurat_dat_comb) <<- rownames(seurat_meta_comb)
seurat_dat_comb
rownames(seurat_dat_comb) <<- rownames(seurat_meta_comb)
seurat_dat_comb <<- as.data.frame(do.call("rbind", all_exprs))
seurat_meta_comb <<- do.call("rbind", meta_file)
rownames(seurat_dat_comb) <<- rownames(seurat_meta_comb)
seurat_meta_comb
seurat_dat_comb
colnames <- colnames(seurat_dat_comb)
checkboxGroupInput("columns", "Select columns for analysis:", choices = colnames, selected = colnames)
print(colnames)
# select columns
seurat_dat_comb <- seurat_dat_comb[, !(colnames(seurat_dat_comb) %in% input$colnames)]
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
test_vec <- c("test", "chat", "proliferation")
"proliferation" %in% seurat_metadata
"proliferation" %in% test_vec
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
test <- read.FCS("~/App_benchmarking_autoflow/Mosmann_rare.fcs")
test <- flowCore::read.FCS("~/App_benchmarking_autoflow/Mosmann_rare.fcs")
test_dat <- data.frame(exprs(test))
test_dat <- data.frame(test@exprs)
test_dat
colnames(test_dat)
test_dat_select <- test_dat[,!(colnames(test_dat) %in% c("FSC.A", "FCS.H", "FCS.W", "SSC.A", "SSC.H",
"SSC.W", "Live_Dead", "Time", "label"))]
colnames(test_dat_select)
test_cluster <- run_unsupervised(test_dat_select)
library(Seurat)
test_cluster <- run_unsupervised(test_dat_select)
ref_seurat <- test_cluster
test_cluster <- run_unsupervised(test_dat_select)
ref_seurat <- test_dat_select
ref_seurat <- NormalizeData(ref_seurat)
ref_seurat <- FindVariableFeatures(ref_seurat)#, loess.span = 10)
ref_seurat <- FindVariableFeatures(ref_seurat)#, loess.span = 10)
source("~/AutoFlowV1Full/dev/run_dev.R", echo=TRUE)
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
# Set options here
options(golem.app.prod = FALSE) # TRUE = production mode, FALSE = development mode
# Comment this if you don't want the app to be served on a random port
options(shiny.port = httpuv::randomPort())
# Detach all loaded packages and clean your environment
golem::detach_all_attached()
# rm(list=ls(all.names = TRUE))
# Document and reload your package
golem::document_and_reload()
# Run the application
run_app()
